# Streamlitç‰ˆ æœ‰æœ›äººæãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ãƒ„ãƒ¼ãƒ«

import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ä»®ã®äººæãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿
data = [
    {"name": "éˆ´æœ¨ èŠ±å­", "affiliation": "æ±äº¬å¤§å­¦ æ¾å°¾ç ”ç©¶å®¤", "skills": "è‡ªç„¶è¨€èªå‡¦ç†, GPT, Python, è«–æ–‡å¤šæ•°", "link": "https://researchmap.jp/hanako_suzuki", "summary": "è‡ªç„¶è¨€èªå‡¦ç†ã«é–¢ã™ã‚‹ç ”ç©¶ã‚’è¡Œã„ã€ç‰¹ã«å¤šè¨€èªå¯¾å¿œã®LLMã«å–ã‚Šçµ„ã‚€ã€‚è«–æ–‡ã‚‚å¤šæ•°ç™ºè¡¨ã€‚"},
    {"name": "ç”°ä¸­ ä¸€éƒ", "affiliation": "äº¬éƒ½å¤§å­¦ æƒ…å ±å­¦ç ”ç©¶ç§‘", "skills": "ç”»åƒèªè­˜, CNN, PyTorch", "link": "https://github.com/ichirotanaka", "summary": "CNNã‚’ç”¨ã„ãŸç”»åƒåˆ†é¡ã®ç ”ç©¶ã«æ³¨åŠ›ã—ã¦ãŠã‚Šã€åŒ»ç™‚ç”»åƒå‡¦ç†ãªã©ã®å¿œç”¨ã«ã‚‚æºã‚ã‚‹ã€‚"},
    {"name": "å±±ç”° å¤ªéƒ", "affiliation": "å¤§é˜ªå¤§å­¦ AIç ”ç©¶ã‚»ãƒ³ã‚¿ãƒ¼", "skills": "ç”ŸæˆAI, Stable Diffusion, Python", "link": "https://researchmap.jp/taro_yamada", "summary": "ç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã«é–¢ã™ã‚‹ç ”ç©¶ã§ã€å¤šæ•°ã®ãƒ‡ãƒ¢ã‚¢ãƒ—ãƒªã‚’é–‹ç™ºã€‚Stable Diffusionã«é–¢å¿ƒã‚ã‚Šã€‚"},
    {"name": "ä½è—¤ ç¾å’²", "affiliation": "æ±äº¬å·¥æ¥­å¤§å­¦ æ•°ç†ãƒ»è¨ˆç®—ç§‘å­¦ç³»", "skills": "æœ€é©åŒ–, æ•°ç†ãƒ¢ãƒ‡ãƒªãƒ³ã‚°, Python", "link": "https://github.com/misaki-sato", "summary": "ä¼æ¥­ã¨ã®å…±åŒç ”ç©¶ã§ç‰©æµæœ€é©åŒ–å•é¡Œã‚’æ‰±ã„ã€å®Ÿè·µçš„ãªæ•°ç†ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã«å¼·ã¿ã€‚"},
    {"name": "ä¸­æ‘ ç¿¼", "affiliation": "æ±åŒ—å¤§å­¦ æƒ…å ±ç§‘å­¦ç ”ç©¶ç§‘", "skills": "å¼·åŒ–å­¦ç¿’, ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹, C++", "link": "https://researchmap.jp/tsubasa_nakamura", "summary": "å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ãŸãƒ­ãƒœãƒƒãƒˆåˆ¶å¾¡ãŒå°‚é–€ã€‚ROSã‚„C++ã‚’ç”¨ã„ãŸå®Ÿæ©Ÿå®Ÿé¨“ã‚‚çµŒé¨“è±Šå¯Œã€‚"},
    {"name": "å°æ— çµè¡£", "affiliation": "æ—©ç¨²ç”°å¤§å­¦ åŸºå¹¹ç†å·¥å­¦éƒ¨", "skills": "ãƒ‡ãƒ¼ã‚¿åˆ†æ, æ©Ÿæ¢°å­¦ç¿’, R, Python", "link": "https://github.com/yui-kobayashi", "summary": "ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰çµŒé¨“ãŒã‚ã‚Šã€Kaggleå‚åŠ çµŒé¨“ã‚ã‚Šã€‚"},
    {"name": "æ¾æœ¬ å¤§åœ°", "affiliation": "ä¹å·å¤§å­¦ çµ±è¨ˆç§‘å­¦ã‚»ãƒ³ã‚¿ãƒ¼", "skills": "çµ±è¨ˆè§£æ, å›å¸°åˆ†æ, R", "link": "https://researchmap.jp/daichi_matsumoto", "summary": "å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚„å› å­åˆ†æãªã©çµ±è¨ˆè§£æã‚’å¾—æ„ã¨ã—ã€æ•™è‚²åˆ†é‡ã¸ã®å¿œç”¨ã«ã‚‚å–ã‚Šçµ„ã‚€ã€‚"},
    {"name": "é«˜æ©‹ ç›´äºº", "affiliation": "åå¤å±‹å¤§å­¦ æƒ…å ±ç§‘å­¦ç ”ç©¶ç§‘", "skills": "è‡ªç„¶è¨€èªå‡¦ç†, æ©Ÿæ¢°ç¿»è¨³, BERT", "link": "https://github.com/naoto-takahashi", "summary": "æ©Ÿæ¢°ç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡ã¨æ”¹è‰¯ã«å–ã‚Šçµ„ã¿ã€BERTãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰çµŒé¨“ã‚ã‚Šã€‚"},
    {"name": "æ— ã•ãã‚‰", "affiliation": "åŒ—æµ·é“å¤§å­¦ AIç ”ç©¶æ‰€", "skills": "æ™‚ç³»åˆ—è§£æ, LSTM, Python", "link": "https://researchmap.jp/sakura_hayashi", "summary": "é‡‘èãƒ‡ãƒ¼ã‚¿ã‚„IoTãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸæ™‚ç³»åˆ—è§£æã®ç ”ç©¶ã«å¾“äº‹ã€‚LSTMã«ã‚ˆã‚‹äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰çµŒé¨“ã‚ã‚Šã€‚"},
    {"name": "é’æœ¨ å¥", "affiliation": "ç­‘æ³¢å¤§å­¦ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ç³»", "skills": "ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°, æ•™å¸«ãªã—å­¦ç¿’, å¯è¦–åŒ–", "link": "https://github.com/ken-aoki", "summary": "æ•™å¸«ãªã—å­¦ç¿’ã«ã‚ˆã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œå‹•ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¨å¯è¦–åŒ–æŠ€è¡“ã«å–ã‚Šçµ„ã‚€ã€‚"}
]

df = pd.DataFrame(data)
df["combined_text"] = df["skills"] + " " + df["summary"]

# Streamlit UI
st.title("ğŸ” æœ‰æœ›äººæãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ãƒ„ãƒ¼ãƒ«")
st.markdown("äººæè¦ä»¶ï¼ˆä¾‹: è‡ªç„¶è¨€èªå‡¦ç† GPT å¤šè¨€èªå¯¾å¿œï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

user_input = st.text_input("äººæè¦ä»¶ã‚’å…¥åŠ›", "è‡ªç„¶è¨€èªå‡¦ç† GPT å¤šè¨€èªå¯¾å¿œ")

if user_input:
    corpus = df["combined_text"].tolist() + [user_input]
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(corpus)

    user_vector = tfidf_matrix[-1]
    profile_vectors = tfidf_matrix[:-1]
    similarities = cosine_similarity(user_vector, profile_vectors).flatten()

    df["match_score"] = similarities
    result = df.sort_values(by="match_score", ascending=False)

    st.subheader("ğŸ“‹ ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰çµæœ")
    st.dataframe(result[["name", "affiliation", "skills", "match_score", "link"]])

